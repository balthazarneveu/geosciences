{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TP 2: segmentation and classification of PreTest signals\n",
    "Balthazar Neveu\n",
    "\n",
    "Topics:\n",
    "-  Noisy labels\n",
    "-  Imbalanced dataset\n",
    "-  Feature extraction\n",
    "-  Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem statement\n",
    "\n",
    "- Total normal samples: 85 = 35.1%\n",
    "- Total tight samples: 157 = 64.9% (*dominant class*)\n",
    "\n",
    "![profiles classification](figures/normalized_profiles_analyzis.png)\n",
    "\n",
    "- Classify a set of pressure profiles.\n",
    "  - üü¢ Green: normal  $\\text{label}=1$\n",
    "  - üî¥ Red: Tight $\\text{label}=0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exploration: Reparameterization and handcrafted features\n",
    "\n",
    "![profiles classification minus trend](figures/normalized_profiles_analyzis_minus_trend.png)\n",
    "\n",
    "- Remove the \"identity trend\"\n",
    "- Maximum value of these curves looks like a good discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exploration: Handcrafted feature\n",
    "\n",
    "![profiles classification](figures/histogram_of_features.png)\n",
    "\n",
    "- Histogram of this handcrafted feature for the 2 labelled classes.\n",
    "- A simple threshold around 0.7 could be enough to discriminate these 2 classes. Simple to compute, yet seems efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exploration: PCA\n",
    "- When we apply a principal component analyzis to the raw curves, we're able to see 2 clusters appear in the 2D eigen cofficient space.\n",
    "- Each pressure curve made of 200 samples has been mapped to a single 2D vector.\n",
    "- Knowing the labels, 2 obvious clusters appear.\n",
    " \n",
    "![pca](figures/pca_curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### 2D Gaussian Fitting\n",
    "\n",
    "![gaussian fit](figures/pca_curves_gmm_fit_1mode.png)\n",
    "\n",
    "- If we reproject the centroid back into the original pressure curve space, we can see that these curves are pretty representative of the 2 distributions in the original space.\n",
    "- These are simple combinations of the 2 eigenvectors.\n",
    "\n",
    "![gaussian fit reproj](figures/pca_curves_gmm_fit_reproj_1mode.png)\n",
    "\n",
    "---------\n",
    "\n",
    "*Please note that [`scikitlearn`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) applies a mean centering to perform PCA* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Fitting a 2D GMM (*Gaussian Mixture Model*)\n",
    "\n",
    "![gaussian fit 2 modes](figures/pca_curves_gmm_fit.png)\n",
    "\n",
    "![gaussian fit 2 modes reproj](figures/pca_curves_gmm_fit_reproj.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification\n",
    "\n",
    "- Precision: classified a normal event as normal $\\frac{tp}{tp+fp}$: *classifier ability not to label as positive a sample that is negative.* üí≤\n",
    "- Recall: classified  $\\frac{tp}{tp+fn}$ : *the classifier ability to find all the positive samples.*. We want a recall of 100% here ‚ùå !\n",
    "- Confusion matrix: $C_{i, j}$\n",
    "  - $i$ groundtruth class\n",
    "  - $j$ predicted class\n",
    "\n",
    "| Confusion matrix | Prediction $j=0$ Tight| Prediction $j=1$ Normal |\n",
    "| :---: | ------ | ------ |\n",
    "|**Groundtruth $i=0$ Tight**| True Negative (groundtruth=tight, prediction=tight) ‚úîÔ∏è | False Positive (groundtruth=tight,prediction=normal) üí≤ |\n",
    "|**Groundtruth $i=1$ Normal**| False Negative (groundtruth=normal, prediction=Tight) ‚ùå | True Positive (groundtruth=normal, prediction=normal) ‚úîÔ∏è |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Study with regard to pressure test length\n",
    "\n",
    "![](figures/perf_fn_by_pressure_test_duration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Study with regard to labelling quality\n",
    "\n",
    "\n",
    "![](figures/perf_fn_by_noisy_label_ratio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Study with regard to dataset imbalance\n",
    "- Does not seem very sensitive.\n",
    "\n",
    "\n",
    "![](figures/perf_fn_by_class_ratio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "- Very low data regime.\n",
    "- Simplicity: Handcrafted features with very basic classifier achieves quite decent results. \n",
    "- False Negative is the most important metric for this topic. False Positives may increase costs.\n",
    "- More work to be done to decrease and reach 0% of false positives, either by adding metadata or making more complex classifiers.\n",
    "- Class imbalance does not seem to affect results too much here. Noisy labels either.\n",
    "- Known method limitations:\n",
    "  - Cross validation is performed by sampling several noisy train sets... while test set remains the same to get a fixed test set reference without noise.\n",
    "  - Not using metatada\n",
    "  - No true way to specifically minimize false negatives. \n",
    "  - *Quid: resampling on time dimension, did we loose information*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to use?\n",
    "- [Notebook](/TP_2/code/TP_2.ipynb)\n",
    "- Command line interface:\n",
    "  - `python TP_2/code/train_classifiers.py --study sequence_lengths_study_noisy -r 20`\n",
    "  - Choices of studies:\n",
    "    - `sequence_lengths_study`: vary pressure test duration, perfect labels, perfect class balance (50%-50%) \n",
    "    - `sequence_lengths_study_noisy`: vary pressure test duration, slightly noisy labels (20%)\n",
    "    - `noisy_labels_study`: study the influence of the amount of noisy labels on final performances.\n",
    "    - `tight_ratio`: tight class ration: variation of class imbalance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
