{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "- [Balthazar Neveu](https://www.linkedin.com/in/balthazarneveu/)\n",
    "- TP-5 [Introduction to geosciences](https://www.master-mva.com/cours/introduction-a-lapprentissage-statistique-pour-les-geosciences/) | ENS Paris Saclay - [Master MVA](https://www.master-mva.com/) 2024\n",
    "- [Web version](https://balthazarneveu.github.io/geosciences) | [Github](https://github.com/balthazarneveu/geoscience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset exploration\n",
    "Pairs of patches and annotations (areas to segment). size 36x36 gray level.\n",
    "\n",
    "- Train set: 7211 patches from 12 wells.\n",
    "- Validation set: 2463 patches from 3 wells (majority in well 13)\n",
    "\n",
    "__Observations__\n",
    "- At first sight, the regions we're trying to segment look like thin dark lines.\n",
    "- Sometimes the positive areas are spread on both sides of the image (due to the circular nature of the well images).\n",
    "- Two images containing NaN values `validation/images/well_15_patch_201.npy` and `well_15_patch_202.npy` are discarded in the dataloader (sanity check before loading the images).\n",
    "\n",
    "![](figures/dataset_samples.png)\n",
    "\n",
    "## Dataloader\n",
    "[data_loader.py](data_loader.py) loads pairs of image, labels.\n",
    "A list of augmentations is provided in [augmentations.py](augmentations.py):\n",
    "- Horizontal roll (since the pipelines are circular)\n",
    "- Vertical/Horizontal flips can be performed randomly.\n",
    "Random augmentations (and shuffles) are only performed on the training set, validation set is frozen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures\n",
    "Three families of models are coded in [model.py](model.py).\n",
    "All models are pretty flexible. \n",
    "What can be changed:\n",
    "- convolution sizes\n",
    "- number of layers\n",
    "- number of channels (hidden dimensions)\n",
    "- activation function (Relu of Leaky ReLu were tested)\n",
    "- number of input channels (ready to apply to other modalities)\n",
    "- number of output channels (ready for multi classes).\n",
    "Since all models inherit from `BaseModel`, the number of parameters and the receptive field can easily be retrieved.\n",
    "Please note that all models do not include the sigmoïd applied to the final layer: we take logits as outputs and the loss function or further inference is in charge of applying the sigmoïd to convert these to probabilities.\n",
    "\n",
    "\n",
    "| Model name | Number of parameters  | Convolution sizes | Number of layers | Activation | Receptive field (H, V) |\n",
    "| :---:| :---:| :---:|  :---:|  :---:| :---:|\n",
    "| Vanilla Stacked convolutions| 260k |  $(3,3)$ | 5 | ReLu | $(11,11)$ |\n",
    "| Stack convolution | 1.904M | $3^{\\circ} \\perp 5$ | 5 | LeakyReLu | $(11,21)$ |\n",
    "|U-Net|  775k | $(3,3)$ | 3 scales | LeakyReLu | $(27, 27)$ |\n",
    "\n",
    "\n",
    "#### Stacked convolution (single scale)\n",
    "- Flexible design with a parameterized amount of layers\n",
    "- Base convolution block is a separable convolution directionwise ($H \\perp V$)\n",
    "  - The horizontal convolution pads using the \"circular\" convolution option which allows dealing with the specificity of dwell images.\n",
    "  - The vertical convolution pads by repeating gray levels.\n",
    "  - This should explain the notation  $3^{\\circ} \\perp 5$\n",
    "- Input modality convolution block allows going from 1 to `h_dim` channels.\n",
    "- Output modality convolution block allows going from `h_dim` channels back to a single channel.\n",
    "- Last layer outputs an image of the same size as the original one. Since we use the BCE Loss with Logits at first, the output of the network are logits (*not probabilities*), Sigmoid is not included.\n",
    "- Possibility to use residual connections when the number of layers is a multiple of 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla convolution stack (single scale)\n",
    "\n",
    "*Remark: I coded the stacked convolution before I re-discovered the slide on the proposed vanilla model (\"baseline\" model from the slides).*\n",
    "\n",
    "Provided as a \"baseline\" model, uses ReLu .\n",
    "![](figures/vanilla_convolution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet\n",
    "- 3 scales.\n",
    "  - $(36, 36) \\rightarrow (18, 18) \\rightarrow (9, 9)$\n",
    "  - Downsample by decimating information (skip 1 pixel over 4)\n",
    "  - Upsample with a bilinear interpolation.\n",
    "  - Concatenate skip connections together. \n",
    "- Large receptive field (27,27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Taining\n",
    "### Defining experiments\n",
    "- An experiment is defined by as specific ID (like 300) and the whole configuration is versioned under git in the [experiments.py](experiments.py) file:\n",
    "    - architecture (model name, number of layers, convolution sizes)\n",
    "    - augmentations\n",
    "    - loss\n",
    "    - hyper parameters\n",
    "- Tracking is performed using [Weights and Biases](https://wandb.ai/balthazarneveu/geosciences-segmentation/workspace?workspace=user-balthazarneveu)\n",
    "\n",
    "\n",
    "### Infrastructure\n",
    "- It is possible to train locally with a Nvidia very tiny GPU T500 with 4Gb of RAM.\n",
    "  - `python TP_5/train.py -e 300 301`\n",
    "  - `-nowb` allows disabling logging to weights and biases for quick prototyping\n",
    "  - `-e` to specify a list of experiments.\n",
    "- The same experiment can be trained on a remote server `python TP_5/remote_training.py -e 300 301 -u kaggle_username -p` \n",
    "- To be able to train on the remote servers of Kaggle with 16Gb of RAM, I customized a remote training template that I wrote ([MVA-Pepites](https://github.com/balthazarneveu/mva_pepites)). I hosted the [dataset](https://www.kaggle.com/datasets/balthazarneveu/mva-geosciences-segmentation-dataset-slb) under Kaggle.\n",
    "It is possible to train several experiments.\n",
    "\n",
    "![remote training](https://github.com/balthazarneveu/mva_pepites/blob/main/illustrations/overview.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "I implemented a set of [metrics](metrics.py) on the validation set:\n",
    "- Accuracy (does not mean much because if the network returns all zeros, the accuracy is around 89%).\n",
    "- Precision , Recall. Recall seems interesting allows having a metric of how well we detected positive areas.\n",
    "- Segmentation specific metrics : Dice loss (also named F1-score) to measure the balance between precision and recall.\n",
    "- IoU (intersection over union).\n",
    "\n",
    "We train the network using BCE loss (with logits). The problem is casted as a per-pixel binary classification (background = 0, foreground = 1). Since the background class is over represented, we can weight the positive class a bit more.\n",
    "The [loss.py](loss.py) file shows the possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "To be able to visualize results, it is possible to perform live inference and compare several models.\n",
    "|![](figures/interactive_demo_browse.gif)| ![](figures/interactive_demo_compare_models.gif) | ![](figures/interactive_demo_shift.gif) | ![](figures/interactive_demo_noise.gif) |\n",
    "|:---:|:---:|\n",
    "| We can browse between images using the left / right arrow  | page up/ page down to switch between models | Slider allow to shift the input horizontally, and add a bit of noise. Inference is performed live on the GPU|\n",
    "\n",
    "\n",
    "`python TP_5/interactive_inference.py -i \"TP_5/data/train/images/well_2*.npy\" -e 200 402 300 --gui mpl --preload`\n",
    "\n",
    "\n",
    "|![](figures/shift_effect.gif) |\n",
    "|:---:|\n",
    "| Our stacked convolution network which uses horizontal convolutions with circular wrapping is able to segment corrosion areas which are located at the image boundary | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analyzis\n",
    "\n",
    "### Color code\n",
    "- Pixels flagged in black or green: correctly labeled (black=background, green=foreground)\n",
    "- Pixels flagged in red: predicted background (0), groundtruth = foreground (1) *a.k.a False Negative*\n",
    "- Pixels flagged in blue: predicted foreground (1), groundtruth = background (0) *a.k.a False Positiive*\n",
    "\n",
    "### Labeling relevance\n",
    "\n",
    "Trying to reach best accuracy may be in vain. As a matter of fact, it seems that sometimes the labels are less relevant than the network prediction.\n",
    "\n",
    "|![](figures/annotations_accuracy.png) | ![](figures/annotations_accuracy_2.png) |\n",
    "|:---:| :----: |\n",
    "| Label mis-location | Label is too thick. Network prediction is more thin and better located. The corrosion line is 2 pixels wide , not 3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
